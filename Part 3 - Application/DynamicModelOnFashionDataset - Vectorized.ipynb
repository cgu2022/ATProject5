{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Keras NN Fashion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eVBo7CUdj7L",
        "outputId": "46d9dc97-f402-478c-94e2-fd517bab4b8d"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in google colab\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in google colab`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxnmJlsDdtDX",
        "outputId": "7b3e59cd-2052-4d8d-eb01-912305b07d17"
      },
      "source": [
        "# MNIST Fashion Dataset.\n",
        "# 60,000 images for testing, 10,000 images for validation/testing\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist  # load dataset\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()  # split into tetsing and training"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-fbCq1cds7Q",
        "outputId": "4183e75e-6b23-4016-8710-f54f6432a021"
      },
      "source": [
        "train_images.shape # 60,000 images, each 28x28 (784 pixels)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VZZmiEoeekq",
        "outputId": "4e2cb272-9db0-4a97-a9a7-53c6521fd8a0"
      },
      "source": [
        "train_images[0,23,23] # value of one pixel (grayscale image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72WLqQrYemKx"
      },
      "source": [
        "# Labels\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4RE89_rMetUO",
        "outputId": "a588c8eb-01b3-4b27-b846-7b39be8afa42"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[1])\n",
        "plt.colorbar()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3tG1U3He4ws"
      },
      "source": [
        "# Data pre-processing\n",
        "train_images = train_images / 255.0 # Change range from 0-255 to 0-1\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbNFo-e6fWl6"
      },
      "source": [
        "#VECTORIZED VERSION\n",
        "@np.vectorize\n",
        "def sigmoid(z):\n",
        "    if z >= 0:\n",
        "      return 1.0 / (1.0 + np.e**(-z))\n",
        "    else:\n",
        "      return np.e**(z) / (1 + np.e**(z))\n",
        "\n",
        "@np.vectorize\n",
        "def sigmoidPrime(z):\n",
        "    # Derivative of Sigmoid Function\n",
        "      return sigmoid(z) * (1-sigmoid(z))\n",
        "\n",
        "class Model3:\n",
        "    def __init__(self, model_structure=[2, 3, 2], modelActivationFunctions=[\"sigmoid\", \"sigmoid\"], sig=None, sigPrime=None):\n",
        "        self.model_structure = model_structure\n",
        "        self.modelActivationFunctions = modelActivationFunctions\n",
        "        self.modelWidth = len(model_structure)\n",
        "\n",
        "        self.sigmoid = sig\n",
        "        self.sigmoidPrime = sigPrime\n",
        "\n",
        "        # Safety Check to make sure model structure is legitimate\n",
        "        if self.modelWidth<3 or self.modelWidth-1!=len(self.modelActivationFunctions):\n",
        "            print(\"Model Structure Error!\")\n",
        "            exit(1)  \n",
        "\n",
        "        # Weights (Parameters) - Randomly Assigned\n",
        "        self.weights = list()\n",
        "        self.weights.append(np.random.randn(self.model_structure[1],self.model_structure[0])) # Input Layer Weights\n",
        "        for i in range(1, self.modelWidth-1):\n",
        "            self.weights.append(np.random.randn(self.model_structure[i+1], self.model_structure[i]))\n",
        "\n",
        "        # Biases - Randomly Assigned\n",
        "        self.biases = list()\n",
        "        for i in range(1, self.modelWidth):\n",
        "            self.biases.append(np.random.randn(self.model_structure[i], 1))  # Length should be number of columns of X\n",
        "        '''self.weights = [np.array(([[0.15, 0.3], [0.2, 0.35], [0.25, 0.4]]), dtype=float), np.array(([[0.5, 0.6, 0.7], [0.55, 0.65, 0.75]]), dtype=float)]\n",
        "        self.biases = [[[0.45], [0.45], [0.45]], [[0.8], [0.8]]]'''\n",
        "    \n",
        "    def softmax(self, x):\n",
        "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "    '''\n",
        "    def softmax(z):\n",
        "        z -= np.max(z)\n",
        "        sm = (np.exp(z).T / np.sum(np.exp(z), axis=0)).T\n",
        "        return sm\n",
        "    '''\n",
        "    def softmaxPrime(self, z):\n",
        "        z -= np.max(z)\n",
        "        sm = (np.exp(z).T / np.sum(np.exp(z), axis=0)).T\n",
        "        s = sm.reshape(-1,1)# Reshape the 1-d softmax to 2-d so that np.dot will do the matrix multiplication\n",
        "        return np.diagflat(s) - np.dot(s, s.T)\n",
        "\n",
        "    def relu(self, z):\n",
        "        return np.maximum(0, z)\n",
        "    \n",
        "    def reluPrime(self, x):\n",
        "        x[x<=0] = 0\n",
        "        x[x>0] = 1\n",
        "        return x\n",
        "    \n",
        "    def applyActivationFunction(self, values, activation):\n",
        "        if activation=='sigmoid':\n",
        "            return self.sigmoid(values)\n",
        "        elif activation=='softmax':\n",
        "            return self.softmax(values)\n",
        "        elif activation=='relu':\n",
        "            return self.relu(values)\n",
        "        else:\n",
        "            print(\"Unknown Activation Function! Got:\", activation)\n",
        "            exit(1)\n",
        "    \n",
        "    def applyActivationFunctionPrime(self, values, activation):\n",
        "        if activation=='sigmoid':\n",
        "            return self.sigmoidPrime(values)\n",
        "        elif activation=='softmax':\n",
        "            return self.softmaxPrime(values)\n",
        "        elif activation=='relu':\n",
        "            return self.reluPrime(values)\n",
        "        else:\n",
        "            print(\"Unknown Activation Function! Got:\", activation)\n",
        "            exit(1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Propogate inputs through networks\n",
        "        self.aValues = list()\n",
        "        self.zValues = list()\n",
        "        self.aValues.append(X) # First a value = input values\n",
        "        for i in range(0, len(self.weights)):\n",
        "            self.zValues.append(np.dot(self.weights[i], self.aValues[i]) + self.biases[i])\n",
        "            self.aValues.append(self.applyActivationFunction(self.zValues[i], self.modelActivationFunctions[i]))\n",
        "        yHat = self.aValues[-1]\n",
        "        return yHat\n",
        "\n",
        "    def costFunction(self, X, y):\n",
        "        # Compute cost using the weights already stored\n",
        "        self.yHat = self.forward(X)\n",
        "        J = 0.5*sum((y-self.yHat)**2)\n",
        "        return J\n",
        "    \n",
        "    def costFunctionPrime(self, X, y):\n",
        "        # Computes partial derivatives of Cost function with respect to weights & biases\n",
        "        self.yHat = self.forward(X)\n",
        "        \n",
        "        weightDerivatives = list() # Derivative of Cost function with respect to weights\n",
        "        biasDerivatives = list() # Derivative of Cost function with respect to biases\n",
        "\n",
        "        # Last Layer derivatives\n",
        "        delta = np.multiply(-(y-self.aValues[-1]), self.sigmoidPrime(self.zValues[-1]))\n",
        "        weightDerivatives.insert(0, np.dot(delta, self.aValues[-2].T))\n",
        "        biasDerivatives.insert(0, delta.sum(axis=1).reshape(delta.shape[0],1)) \n",
        "        \n",
        "        # Derivatives for the other layers (L-1, L-2, ...)\n",
        "        for i in range(self.modelWidth-2, 0, -1):\n",
        "            delta = np.multiply(np.dot(self.weights[i].T, delta), self.applyActivationFunctionPrime(self.zValues[i-1], self.modelActivationFunctions[i])) \n",
        "            weightDerivatives.insert(0, np.dot(delta, self.aValues[i-1].T))\n",
        "            biasDerivatives.insert(0, delta.sum(axis=1).reshape(delta.shape[0],1))\n",
        "\n",
        "        return weightDerivatives, biasDerivatives\n",
        "    \n",
        "    def tuneParams(self, X, y, learning_rate=0.5, getLoss=False):\n",
        "        # Get Derivatives of Weights & Biases, and then adjust weights/biases with learning rate*derivatives\n",
        "        # getLoss: if you want to calculate loss (before adjusting weights)\n",
        "        self.weightDerivatives, self.biasDerivatives = self.costFunctionPrime(X, y)\n",
        "        \n",
        "        loss = None\n",
        "        if getLoss:\n",
        "           loss = ((y-self.yHat)**2)/2\n",
        "           # print(X.shape)\n",
        "           loss = loss.sum()/X.shape[1]\n",
        "\n",
        "        scalar = learning_rate # learning rate divided by number of samples\n",
        "        for i in range(0, len(self.weights)):\n",
        "            self.weights[i] = self.weights[i] - (scalar*self.weightDerivatives[i] / X.shape[1])\n",
        "            self.biases[i] = self.biases[i] - (scalar*self.biasDerivatives[i] / X.shape[1])\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    def one_hot_encoder(self, expected):\n",
        "        # formats label into array of zeros except for the index of the correct prediction\n",
        "        #expected = expected.to_numpy()\n",
        "        expected = expected.reshape(expected.shape[0],)\n",
        "        b = np.zeros((expected.size, int(expected.max()+1)))\n",
        "        b[np.arange(expected.size), expected] = 1\n",
        "        return b.T\n",
        "\n",
        "    def fit(self, X, y, TestDataX=None, TestDatay=None, learning_rate=0.5, epochs=10, batch_size=32, flatten=False, stagger=True):\n",
        "        # X: Training Data\n",
        "        # y: Labels for Training Data\n",
        "        # TestingDataX: Testing Data (if staggering)\n",
        "        # TestingDatay: Labels for Testing Data (if staggering)\n",
        "        # learning_rate: rate at which to update the weights with their derivatives\n",
        "        # epochs: number of \"runs\" to execute. Each run is going through the entire dataset once\n",
        "        # batch_size: number of samples to go through before tuning parameters\n",
        "        # Flatten: if each sample of the test data needs to be flatten (like if each sample is an image)\n",
        "        # Stagger: if to test model after every epoch\n",
        "\n",
        "        if X.shape[0] % batch_size != 0:\n",
        "          print(\"# of training samples isn't divisible by entered batch size!\")\n",
        "          exit(1)\n",
        "        \n",
        "        if stagger and ((TestDataX is None) or (TestDatay is None)):\n",
        "          print(\"You can't stagger when you don't pass in testing data and/or it's labels!\")\n",
        "          exit(1)\n",
        "\n",
        "        if flatten:\n",
        "          inputNumber = 1\n",
        "          #print(X.shape)\n",
        "          for i in range(1, len(X.shape)):\n",
        "            inputNumber*=X.shape[i]\n",
        "          X = X.reshape(X.shape[0], inputNumber)\n",
        "          #print(X.shape)\n",
        "          TestDataX = TestDataX.reshape(TestDataX.shape[0], inputNumber)\n",
        "        \n",
        "        y_formatted = self.one_hot_encoder(train_labels)\n",
        "        loss_list_average = list() # Keeps all the average losses from each epoch\n",
        "        train_accuracies = list() # Keeps all the training accuracies from each epoch (which is apparently: (1-averageLoss))\n",
        "        test_accuracies = list() # Keeps all the testing accuracies from each epoch\n",
        "        for i in range(1, epochs+1):\n",
        "          print(\"Epoch:\", i)\n",
        "          loss_list = list() # This is for keeping all the losses from each batch in the epoch; used to calculate lost_list_average\n",
        "          for j in range(1, int(X.shape[0]/batch_size)+1): # Going through each batch\n",
        "            if j%int((int(X.shape[0]/batch_size)/10)) == 0:\n",
        "              print(\"Iteration:\", j)\n",
        "            # Slice appropriate batch sizes\n",
        "            X_batch = X[(j-1)*batch_size : j*batch_size].T #'''Why do we need to transpose here???'''\n",
        "            # print(y_formatted.shape)\n",
        "            y_batch_formatted = y_formatted[:, (j-1)*batch_size : j*batch_size]\n",
        "            # print(y_batch_formatted.shape)\n",
        "            # Training & Getting Loss\n",
        "            loss = self.tuneParams(X_batch, y_batch_formatted, learning_rate, getLoss=True)\n",
        "            # print(\"Loss:\", loss)\n",
        "            loss_list.append(loss)\n",
        "          # print(model.weights)\n",
        "          loss_list_average.append((sum(loss_list)/len(loss_list)))\n",
        "          train_accuracies.append(1 - loss_list_average[i-1])\n",
        "          print(\"Average loss across batches:\", loss_list_average[i-1])\n",
        "          print(\"Training Accuracy:\", train_accuracies[i-1])\n",
        "\n",
        "          if stagger:\n",
        "            outputs = self.forward(TestDataX.T)\n",
        "            # print(outputs.shape)\n",
        "            predictions = list()\n",
        "            outputs = outputs.T\n",
        "            for output in outputs: # Going through output for each sample to format prediction\n",
        "              #print(output)\n",
        "              predictions.append(np.argmax(output))\n",
        "            numberOfCorrect = 0\n",
        "            # print(len(predictions))\n",
        "            # print(TestDatay.shape)\n",
        "            for j in range(0, len(TestDatay)): # Calculating the accruacy\n",
        "              # print(str(j)+\"|\", \"Prediction:\", predictions[j], \"Actual:\", TestDatay[j])\n",
        "              if TestDatay[j] == predictions[j]:\n",
        "                numberOfCorrect+=1\n",
        "            print(\"Number of Correct:\", numberOfCorrect)\n",
        "            print(\"Total Number:\", len(TestDatay))\n",
        "            testAccuracy = numberOfCorrect/len(TestDatay)\n",
        "            print(\"Testing Accuracy:\", testAccuracy)\n",
        "            test_accuracies.append(testAccuracy)\n",
        "          print()\n",
        "          \n",
        "          # Shuffling\n",
        "          # print(X.shape)\n",
        "          # print(y_formatted.shape)\n",
        "          X_shuffled, y_formatted_shuffled = shuffle(X, y_formatted.T, random_state=0)\n",
        "          X = X_shuffled\n",
        "          y_formatted = y_formatted_shuffled.T\n",
        "\n",
        "        return loss_list_average, train_accuracies, test_accuracies\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-5fPFyHjceF"
      },
      "source": [
        "model = Model3(model_structure=[784, 128, 10], modelActivationFunctions=['relu', 'sigmoid'], sig=sigmoid, sigPrime=sigmoidPrime)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANoD1Xumkkqs",
        "outputId": "932a9fbc-1f2e-4dad-eab0-8782d8a5fa95"
      },
      "source": [
        "# Training the model\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels)\n",
        "\n",
        "model.fit(train_images, train_labels, test_images, test_labels, learning_rate=0.01, epochs=10, batch_size=32, flatten=True, stagger=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Iteration: 187\n",
            "Iteration: 374\n",
            "Iteration: 561\n",
            "Iteration: 748\n",
            "Iteration: 935\n",
            "Iteration: 1122\n",
            "Iteration: 1309\n",
            "Iteration: 1496\n",
            "Iteration: 1683\n",
            "Iteration: 1870\n",
            "Average loss across batches: 1.739031203484398\n",
            "Training Accuracy: -0.739031203484398\n",
            "Number of Correct: 1002\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1002\n",
            "\n",
            "Epoch: 2\n",
            "Iteration: 187\n",
            "Iteration: 374\n",
            "Iteration: 561\n",
            "Iteration: 748\n",
            "Iteration: 935\n",
            "Iteration: 1122\n",
            "Iteration: 1309\n",
            "Iteration: 1496\n",
            "Iteration: 1683\n",
            "Iteration: 1870\n",
            "Average loss across batches: 0.9872659671793507\n",
            "Training Accuracy: 0.012734032820649333\n",
            "Number of Correct: 1004\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1004\n",
            "\n",
            "Epoch: 3\n",
            "Iteration: 187\n",
            "Iteration: 374\n",
            "Iteration: 561\n",
            "Iteration: 748\n",
            "Iteration: 935\n",
            "Iteration: 1122\n",
            "Iteration: 1309\n",
            "Iteration: 1496\n",
            "Iteration: 1683\n",
            "Iteration: 1870\n",
            "Average loss across batches: 0.9201508176145284\n",
            "Training Accuracy: 0.07984918238547156\n",
            "Number of Correct: 1004\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1004\n",
            "\n",
            "Epoch: 4\n",
            "Iteration: 187\n",
            "Iteration: 374\n",
            "Iteration: 561\n",
            "Iteration: 748\n",
            "Iteration: 935\n",
            "Iteration: 1122\n",
            "Iteration: 1309\n",
            "Iteration: 1496\n",
            "Iteration: 1683\n",
            "Iteration: 1870\n",
            "Average loss across batches: 0.9107811150603118\n",
            "Training Accuracy: 0.08921888493968821\n",
            "Number of Correct: 1005\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1005\n",
            "\n",
            "Epoch: 5\n",
            "Iteration: 187\n",
            "Iteration: 374\n",
            "Iteration: 561\n",
            "Iteration: 748\n",
            "Iteration: 935\n",
            "Iteration: 1122\n",
            "Iteration: 1309\n",
            "Iteration: 1496\n",
            "Iteration: 1683\n",
            "Iteration: 1870\n",
            "Average loss across batches: 0.9066966497816988\n",
            "Training Accuracy: 0.09330335021830116\n",
            "Number of Correct: 1007\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1007\n",
            "\n",
            "Epoch: 6\n",
            "Iteration: 187\n",
            "Iteration: 374\n",
            "Iteration: 561\n",
            "Iteration: 748\n",
            "Iteration: 935\n",
            "Iteration: 1122\n",
            "Iteration: 1309\n",
            "Iteration: 1496\n",
            "Iteration: 1683\n",
            "Iteration: 1870\n",
            "Average loss across batches: 0.9041864150277211\n",
            "Training Accuracy: 0.09581358497227888\n",
            "Number of Correct: 1007\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1007\n",
            "\n",
            "Epoch: 7\n",
            "Iteration: 187\n",
            "Iteration: 374\n",
            "Iteration: 561\n",
            "Iteration: 748\n",
            "Iteration: 935\n",
            "Iteration: 1122\n",
            "Iteration: 1309\n",
            "Iteration: 1496\n",
            "Iteration: 1683\n",
            "Iteration: 1870\n",
            "Average loss across batches: 0.9023380474161983\n",
            "Training Accuracy: 0.09766195258380173\n",
            "Number of Correct: 1010\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.101\n",
            "\n",
            "Epoch: 8\n",
            "Iteration: 187\n",
            "Iteration: 374\n",
            "Iteration: 561\n",
            "Iteration: 748\n",
            "Iteration: 935\n",
            "Iteration: 1122\n",
            "Iteration: 1309\n",
            "Iteration: 1496\n",
            "Iteration: 1683\n",
            "Iteration: 1870\n",
            "Average loss across batches: 0.9009774655876592\n",
            "Training Accuracy: 0.09902253441234077\n",
            "Number of Correct: 1011\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1011\n",
            "\n",
            "Epoch: 9\n",
            "Iteration: 187\n",
            "Iteration: 374\n",
            "Iteration: 561\n",
            "Iteration: 748\n",
            "Iteration: 935\n",
            "Iteration: 1122\n",
            "Iteration: 1309\n",
            "Iteration: 1496\n",
            "Iteration: 1683\n",
            "Iteration: 1870\n",
            "Average loss across batches: 0.8997818015790944\n",
            "Training Accuracy: 0.10021819842090562\n",
            "Number of Correct: 1014\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1014\n",
            "\n",
            "Epoch: 10\n",
            "Iteration: 187\n",
            "Iteration: 374\n",
            "Iteration: 561\n",
            "Iteration: 748\n",
            "Iteration: 935\n",
            "Iteration: 1122\n",
            "Iteration: 1309\n",
            "Iteration: 1496\n",
            "Iteration: 1683\n",
            "Iteration: 1870\n",
            "Average loss across batches: 0.8986883923128152\n",
            "Training Accuracy: 0.10131160768718483\n",
            "Number of Correct: 1014\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1014\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1.739031203484398,\n",
              "  0.9872659671793507,\n",
              "  0.9201508176145284,\n",
              "  0.9107811150603118,\n",
              "  0.9066966497816988,\n",
              "  0.9041864150277211,\n",
              "  0.9023380474161983,\n",
              "  0.9009774655876592,\n",
              "  0.8997818015790944,\n",
              "  0.8986883923128152],\n",
              " [-0.739031203484398,\n",
              "  0.012734032820649333,\n",
              "  0.07984918238547156,\n",
              "  0.08921888493968821,\n",
              "  0.09330335021830116,\n",
              "  0.09581358497227888,\n",
              "  0.09766195258380173,\n",
              "  0.09902253441234077,\n",
              "  0.10021819842090562,\n",
              "  0.10131160768718483],\n",
              " [0.1002,\n",
              "  0.1004,\n",
              "  0.1004,\n",
              "  0.1005,\n",
              "  0.1007,\n",
              "  0.1007,\n",
              "  0.101,\n",
              "  0.1011,\n",
              "  0.1014,\n",
              "  0.1014])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JacuuCk6s0jw"
      },
      "source": [
        "model = Model3(model_structure=[784, 128, 10], modelActivationFunctions=['relu', 'sigmoid']) # Another test"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1pWLQqcOOEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2fadaa5-d634-4006-ddad-8d9cec33dffc"
      },
      "source": [
        "# Training the model\r\n",
        "\r\n",
        "(train_images, train_labels), (test_images, test_labels)\r\n",
        "\r\n",
        "model.fit(train_images, train_labels, test_images, test_labels, learning_rate=0.01, epochs=10, batch_size=32, flatten=True, stagger=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: RuntimeWarning: overflow encountered in square\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average loss across batches: 1.127746841487802\n",
            "Training Accuracy: -0.12774684148780202\n",
            "Number of Correct: 1577\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1577\n",
            "\n",
            "Epoch: 2\n",
            "Average loss across batches: 0.5479248235545682\n",
            "Training Accuracy: 0.4520751764454318\n",
            "Number of Correct: 1799\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1799\n",
            "\n",
            "Epoch: 3\n",
            "Average loss across batches: 0.5199435405142032\n",
            "Training Accuracy: 0.4800564594857968\n",
            "Number of Correct: 1878\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1878\n",
            "\n",
            "Epoch: 4\n",
            "Average loss across batches: 0.5110870566022259\n",
            "Training Accuracy: 0.48891294339777414\n",
            "Number of Correct: 1943\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1943\n",
            "\n",
            "Epoch: 5\n",
            "Average loss across batches: 0.5059015155535658\n",
            "Training Accuracy: 0.4940984844464342\n",
            "Number of Correct: 1979\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.1979\n",
            "\n",
            "Epoch: 6\n",
            "Average loss across batches: 0.502763514000012\n",
            "Training Accuracy: 0.49723648599998804\n",
            "Number of Correct: 2002\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.2002\n",
            "\n",
            "Epoch: 7\n",
            "Average loss across batches: 0.5000992457414055\n",
            "Training Accuracy: 0.4999007542585945\n",
            "Number of Correct: 2031\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.2031\n",
            "\n",
            "Epoch: 8\n",
            "Average loss across batches: 0.4974872605834454\n",
            "Training Accuracy: 0.5025127394165546\n",
            "Number of Correct: 2028\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.2028\n",
            "\n",
            "Epoch: 9\n",
            "Average loss across batches: 0.4948856337601316\n",
            "Training Accuracy: 0.5051143662398684\n",
            "Number of Correct: 2042\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.2042\n",
            "\n",
            "Epoch: 10\n",
            "Average loss across batches: 0.49213885363745\n",
            "Training Accuracy: 0.50786114636255\n",
            "Number of Correct: 2053\n",
            "Total Number: 10000\n",
            "Testing Accuracy: 0.2053\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1.127746841487802,\n",
              "  0.5479248235545682,\n",
              "  0.5199435405142032,\n",
              "  0.5110870566022259,\n",
              "  0.5059015155535658,\n",
              "  0.502763514000012,\n",
              "  0.5000992457414055,\n",
              "  0.4974872605834454,\n",
              "  0.4948856337601316,\n",
              "  0.49213885363745],\n",
              " [-0.12774684148780202,\n",
              "  0.4520751764454318,\n",
              "  0.4800564594857968,\n",
              "  0.48891294339777414,\n",
              "  0.4940984844464342,\n",
              "  0.49723648599998804,\n",
              "  0.4999007542585945,\n",
              "  0.5025127394165546,\n",
              "  0.5051143662398684,\n",
              "  0.50786114636255],\n",
              " [0.1577,\n",
              "  0.1799,\n",
              "  0.1878,\n",
              "  0.1943,\n",
              "  0.1979,\n",
              "  0.2002,\n",
              "  0.2031,\n",
              "  0.2028,\n",
              "  0.2042,\n",
              "  0.2053])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}